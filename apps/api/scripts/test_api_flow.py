#!/usr/bin/env python3
"""
Test full API flow: Upload document ‚Üí Index ‚Üí Query
"""

import sys
import asyncio
import time
from pathlib import Path

# Add app to path
sys.path.insert(0, str(Path(__file__).parent.parent))

async def test_full_flow():
    """Test complete RAG flow"""
    print("=" * 70)
    print("üß™ SmartFAQ - Full API Flow Test")
    print("=" * 70)
    
    # Step 1: Test embeddings
    print("\nüìä Step 1: Testing Embeddings...")
    from app.rag.embedder import get_embeddings
    
    embeddings = get_embeddings()
    test_query = "H·ªçc ph√≠ ƒë·∫°i h·ªçc Greenwich l√† bao nhi√™u?"
    query_vector = embeddings.embed_query(test_query)
    print(f"‚úÖ Query embedded: {len(query_vector)} dimensions")
    print(f"   Query: '{test_query}'")
    
    # Step 2: Create test documents
    print("\nüìù Step 2: Creating Test Documents...")
    from langchain_core.documents import Document
    
    test_docs = [
        Document(
            page_content="H·ªçc ph√≠ ƒë·∫°i h·ªçc Greenwich Vi·ªát Nam nƒÉm 2024 l√† 52 tri·ªáu ƒë·ªìng/nƒÉm cho c√°c ng√†nh kinh t·∫ø. Sinh vi√™n c√≥ th·ªÉ ƒëƒÉng k√Ω h·ªçc theo h·ªçc k·ª≥ ho·∫∑c theo nƒÉm.",
            metadata={
                "source": "handbook_2024.pdf",
                "page": 15,
                "document_id": "test-doc-1",
                "chunk_index": 0,
                "chunk_id": "test-chunk-1",
                "title": "S·ªï tay sinh vi√™n 2024"
            }
        ),
        Document(
            page_content="ƒê·ªÉ ƒëƒÉng k√Ω h·ªçc, sinh vi√™n c·∫ßn ƒëƒÉng nh·∫≠p v√†o h·ªá th·ªëng Greenwich Online, ch·ªçn m√¥n h·ªçc v√† x√°c nh·∫≠n ƒëƒÉng k√Ω. Th·ªùi gian ƒëƒÉng k√Ω h·ªçc t·ª´ ng√†y 1-15 m·ªói th√°ng.",
            metadata={
                "source": "enrollment_guide.pdf",
                "page": 5,
                "document_id": "test-doc-2",
                "chunk_index": 0,
                "chunk_id": "test-chunk-2",
                "title": "H∆∞·ªõng d·∫´n ƒëƒÉng k√Ω h·ªçc"
            }
        ),
        Document(
            page_content="Th∆∞ vi·ªán Greenwich m·ªü c·ª≠a t·ª´ 7h00 ƒë·∫øn 21h00 c√°c ng√†y trong tu·∫ßn. Sinh vi√™n c√≥ th·ªÉ m∆∞·ª£n t·ªëi ƒëa 5 cu·ªën s√°ch trong 2 tu·∫ßn.",
            metadata={
                "source": "library_rules.pdf",
                "page": 1,
                "document_id": "test-doc-3",
                "chunk_index": 0,
                "chunk_id": "test-chunk-3",
                "title": "Quy ƒë·ªãnh th∆∞ vi·ªán"
            }
        ),
        Document(
            page_content="H·ªçc b·ªïng Greenwich d√†nh cho sinh vi√™n c√≥ th√†nh t√≠ch h·ªçc t·∫≠p xu·∫•t s·∫Øc. M·ª©c h·ªçc b·ªïng t·ª´ 30% ƒë·∫øn 100% h·ªçc ph√≠. H·∫°n n·ªôp h·ªì s∆° l√† ng√†y 31/8 h√†ng nƒÉm.",
            metadata={
                "source": "scholarship_info.pdf",
                "page": 2,
                "document_id": "test-doc-4",
                "chunk_index": 0,
                "chunk_id": "test-chunk-4",
                "title": "Th√¥ng tin h·ªçc b·ªïng"
            }
        ),
        Document(
            page_content="ƒê·ªÉ li√™n h·ªá ph√≤ng tuy·ªÉn sinh, sinh vi√™n c√≥ th·ªÉ g·ªçi hotline 1900-6013 ho·∫∑c email tuyensinh@greenwich.edu.vn. Ph√≤ng tuy·ªÉn sinh l√†m vi·ªác t·ª´ th·ª© 2 ƒë·∫øn th·ª© 6.",
            metadata={
                "source": "contact_info.pdf",
                "page": 1,
                "document_id": "test-doc-5",
                "chunk_index": 0,
                "chunk_id": "test-chunk-5",
                "title": "Th√¥ng tin li√™n h·ªá"
            }
        ),
    ]
    
    print(f"‚úÖ Created {len(test_docs)} test documents")
    for i, doc in enumerate(test_docs, 1):
        print(f"   {i}. {doc.metadata.get('title')} - {len(doc.page_content)} chars")
    
    # Step 3: Index documents to vector store
    print("\nüóÑÔ∏è  Step 3: Indexing Documents to Chroma...")
    from app.rag.vector_store import get_vectorstore, upsert_documents
    
    try:
        upsert_documents(test_docs)
        print(f"‚úÖ Indexed {len(test_docs)} documents")
        
        # Verify indexing
        vs = get_vectorstore()
        total_count = vs._collection.count()
        print(f"‚úÖ Total documents in collection: {total_count}")
    except Exception as e:
        print(f"‚ùå Indexing failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Step 4: Test retrieval
    print("\nüîç Step 4: Testing Retrieval...")
    from app.rag.retriever import Retriever
    
    retriever = Retriever()
    
    test_queries = [
        "H·ªçc ph√≠ Greenwich l√† bao nhi√™u?",
        "L√†m sao ƒë·ªÉ ƒëƒÉng k√Ω h·ªçc?",
        "Th∆∞ vi·ªán m·ªü c·ª≠a l√∫c m·∫•y gi·ªù?",
        "C√≥ h·ªçc b·ªïng kh√¥ng?",
    ]
    
    for query in test_queries:
        print(f"\n   Query: '{query}'")
        contexts = retriever.retrieve(query, top_k=3, with_score=True)
        
        if contexts:
            print(f"   ‚úÖ Found {len(contexts)} results")
            for i, ctx in enumerate(contexts[:2], 1):
                score = ctx.get('score', 0)
                title = ctx.get('metadata', {}).get('title', 'N/A')
                text_preview = ctx.get('text', '')[:80] + "..."
                print(f"      {i}. Score: {score:.3f} | {title}")
                print(f"         {text_preview}")
        else:
            print(f"   ‚ö†Ô∏è  No results found")
    
    # Step 5: Test confidence calculation
    print("\nüìà Step 5: Testing Confidence Calculation...")
    
    for query in test_queries[:2]:
        contexts = retriever.retrieve(query, top_k=5, with_score=True)
        confidence = retriever.calculate_confidence(contexts)
        print(f"   Query: '{query}'")
        print(f"   Confidence: {confidence:.3f}")
        
        if confidence >= 0.65:
            print(f"   ‚úÖ High confidence - will generate answer")
        else:
            print(f"   ‚ö†Ô∏è  Low confidence - may trigger fallback")
    
    # Step 6: Test LLM answer generation
    print("\nü§ñ Step 6: Testing LLM Answer Generation...")
    from app.rag.llm import LLMWrapper
    
    llm = LLMWrapper()
    
    for query in test_queries[:2]:
        print(f"\n   Query: '{query}'")
        contexts = retriever.retrieve(query, top_k=3, with_score=True)
        
        if contexts:
            answer = await llm.generate_answer_async(query, contexts)
            print(f"   Answer: {answer}")
        else:
            print(f"   ‚ö†Ô∏è  No contexts to generate answer")
    
    # Step 7: Test full RAG orchestrator
    print("\nüîÑ Step 7: Testing Full RAG Orchestrator...")
    from app.rag.orchestrator import RAGOrchestrator
    
    orch = RAGOrchestrator()
    
    for query in test_queries:
        print(f"\n   Query: '{query}'")
        result = await orch.query(
            question=query,
            top_k=5,
            return_top_sources=2
        )
        
        print(f"   ‚úÖ Response:")
        print(f"      Answer: {result['answer'][:150]}...")
        print(f"      Confidence: {result['confidence']:.3f}")
        print(f"      Fallback: {result['fallback_triggered']}")
        print(f"      Latency: {result['latency_ms']}ms")
        print(f"      Sources: {len(result['sources'])}")
        
        for i, src in enumerate(result['sources'], 1):
            print(f"         {i}. {src.get('source')} (score: {src.get('score', 0):.3f})")
    
    # Step 8: Test LCEL chain
    print("\n‚õìÔ∏è  Step 8: Testing LCEL Chain...")
    
    rag_chain = orch.build_rag_chain(k=3)
    
    test_chain_query = "H·ªçc ph√≠ l√† bao nhi√™u?"
    print(f"   Query: '{test_chain_query}'")
    
    chain_answer = await rag_chain.ainvoke(test_chain_query)
    print(f"   ‚úÖ Chain Answer: {chain_answer[:200]}...")
    
    # Summary
    print("\n" + "=" * 70)
    print("üìä Test Summary")
    print("=" * 70)
    print("‚úÖ Embeddings: Working")
    print("‚úÖ Document Indexing: Working")
    print("‚úÖ Retrieval: Working")
    print("‚úÖ Confidence Calculation: Working")
    print("‚úÖ LLM Generation: Working")
    print("‚úÖ RAG Orchestrator: Working")
    print("‚úÖ LCEL Chain: Working")
    print("\nüéâ All tests passed! Full API flow is working correctly.")
    
    return True


if __name__ == "__main__":
    try:
        result = asyncio.run(test_full_flow())
        sys.exit(0 if result else 1)
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Test interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
