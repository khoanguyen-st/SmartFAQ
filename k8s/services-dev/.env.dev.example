# ===================================
# SmartFAQ API - Development Environment Variables
# ===================================
# Copy this file to .env.dev and fill in the values

# ===================================
# Database Configuration
# ===================================
# PostgreSQL connection string for Kubernetes
# Service name: postgres-smartfaq-postgresql.smartfaq-dev.svc.cluster.local
DATABASE_URL=postgresql+psycopg://postgres:smartfaq_dev_postgres_pass_2024@postgres-smartfaq-postgresql.smartfaq-dev.svc.cluster.local:5432/smartfaq_dev

# ===================================
# Redis/Celery Configuration
# ===================================
# Redis connection for Celery (background tasks)
# Service name: redis-smartfaq-master.smartfaq-dev.svc.cluster.local
CELERY_BROKER_URL=redis://:smartfaq_dev_redis_pass_2024@redis-smartfaq-master.smartfaq-dev.svc.cluster.local:6379/0
CELERY_RESULT_BACKEND=redis://:smartfaq_dev_redis_pass_2024@redis-smartfaq-master.smartfaq-dev.svc.cluster.local:6379/0

# ===================================
# API Server Settings
# ===================================
API_HOST=0.0.0.0
API_PORT=8000

# ===================================
# Security & Authentication
# ===================================
# IMPORTANT: Generate a strong random secret for production!
# Use: openssl rand -hex 32
JWT_SECRET=CHANGE_ME_GENERATE_RANDOM_SECRET
JWT_EXPIRE_MINUTES=1440

# Default Admin User (for initial migration)
# IMPORTANT: Change these credentials in production!
ADMIN_DEFAULT_USERNAME=admin
ADMIN_DEFAULT_EMAIL=admin@smartfaq.dev
ADMIN_DEFAULT_PASSWORD=CHANGE_ME_STRONG_PASSWORD

# ===================================
# Google Gemini LLM Configuration
# ===================================
# Get your API key from: https://aistudio.google.com/app/apikey
# IMPORTANT: Keep this secret! Never commit to git!
GOOGLE_API_KEY=YOUR_GOOGLE_API_KEY_HERE

# Model selection (see: https://ai.google.dev/gemini-api/docs/models)
# Options: gemini-2.0-flash-exp, gemini-1.5-flash, gemini-1.5-pro
LLM_MODEL=gemini-2.0-flash-exp
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=2048

# ===================================
# Embeddings Configuration (HuggingFace)
# ===================================
# Using multilingual-e5-base for local embeddings
# Model card: https://huggingface.co/intfloat/multilingual-e5-base
EMBED_MODEL=intfloat/multilingual-e5-base
EMBED_DEVICE=cpu
EMBED_NORMALIZE=true
EMBED_BATCH=32

# ===================================
# RAG System Settings
# ===================================
CONFIDENCE_THRESHOLD=0.65
MAX_CONTEXT_CHARS=8000
TOP_K_RETRIEVAL=5

# ===================================
# Document Upload Settings
# ===================================
# In Kubernetes, this should be /app/uploads (mounted from PVC)
UPLOAD_DIR=/app/uploads
UPLOAD_MAX_MB=50

# ===================================
# Optional: Logging Configuration
# ===================================
# LOG_LEVEL=INFO
# LOG_FORMAT=json

# ===================================
# Optional: CORS Configuration
# ===================================
# CORS_ORIGINS=["https://smartfaq.dev.devplus.edu.vn"]
# CORS_ALLOW_CREDENTIALS=true
